<!--
Sync Impact Report (Constitution v3.1.0):
- Version change: 3.0.0 ‚Üí 3.1.0 (MINOR - Refines Phase III specifications for Hackathon II alignment)
- Reason: Post-planning review to align constitution with actual Phase III implementation requirements
- Modified principles:
  - I. Spec-Driven Development: Clarified two-location spec management (specs/001-phase-3-chatbot/ and specs/features/phase-3-chatbot/)
  - XIII. AI Agent Architecture: Updated with exact OpenAI Agents SDK initialization from quickstart.md
  - XIV. MCP Server Design: Verified exact tool schemas match Hackathon II requirements
  - XV. Conversation State Management: Aligned with actual database schema from data-model.md
  - XVIII. Observability: Added specific trace_id format and logging requirements from Phase III specs
- Clarified sections:
  - Technology Standards: Confirmed OpenAI Agents SDK, Official MCP SDK, GPT-4-turbo
  - Development Workflow: Added Phase III-specific workflow steps (agent testing, MCP tool validation)
  - Project Structure: Updated to show both spec directories coexisting
- Implementation Status Added:
  - Phase I: COMPLETE (87 tests, 77% coverage)
  - Phase II: COMPLETE (Full-stack with auth)
  - Phase III: PLANNED (40 tasks defined, ready for implementation)
  - Phase IV, V: PLANNED (not started)
- Templates requiring updates:
  - ‚úÖ spec-template.md: Already includes MCP tool sections
  - ‚úÖ plan-template.md: Already includes AI/Agent sections
  - ‚úÖ tasks-template.md: Already includes Agent behavior categories
- Follow-up TODOs:
  - Execute /sp.implement to begin Phase III implementation
  - Create backend/src/models/conversation.py with Conversation and Message models
  - Create backend/src/services/agent_service.py with OpenAI Agents SDK wrapper
  - Create backend/src/services/mcp_service.py with 5 MCP tools (add_task, list_tasks, complete_task, delete_task, update_task)
  - Create backend/src/api/chat.py with POST /api/{user_id}/chat endpoint
  - Create frontend/src/components/ChatBot.tsx with ChatKit integration
  - Run database migration for conversation tables
  - Write comprehensive tests for agent behavior and MCP tools
-->

# MA-TODO-APP Constitution - Evolution of Todo (Hackathon II)

**Project**: Todo App Evolution (CLI ‚Üí Web ‚Üí AI Chatbot ‚Üí Kubernetes ‚Üí Cloud)
**Hackathon**: Panaversity Hackathon II - AI-Native Development
**Timeline**: Phase I (Dec 7) ‚Üí Phase II (Dec 14) ‚Üí Phase III (Dec 21) ‚Üí Phase IV (Jan 4) ‚Üí Phase V (Jan 18)
**Points**: 1000 base + 600 bonus = 1600 total possible

## Implementation Status

| Phase | Status | Description | Points | Completed |
|-------|--------|-------------|--------|-----------|
| **Phase I** | ‚úÖ **COMPLETE** | In-Memory Python Console App | 100 | Dec 6, 2025 |
| **Phase II** | ‚úÖ **COMPLETE** | Full-Stack Web Application (Next.js + FastAPI + Neon + Better Auth) | 150 | Dec 13, 2025 |
| **Phase III** | üöß **PLANNED** | AI-Powered Todo Chatbot (OpenAI Agents SDK + MCP) | 200 | In Progress |
| **Phase IV** | üìã **PLANNED** | Local Kubernetes Deployment (Minikube + Helm) | 250 | Not Started |
| **Phase V** | üìã **PLANNED** | Advanced Cloud Deployment (DOKS + Kafka + Dapr) | 300 | Not Started |

**Current Phase**: Phase III implementation beginning
**Deadline**: December 21, 2025 (8 days remaining)
**Ready for**: `/sp.implement` execution with 40 tasks defined

---

## Core Principles

### I. Spec-Driven Development (NON-NEGOTIABLE)
All features MUST be specified before implementation. No code shall be written without a corresponding specification. Specifications are organized in TWO locations for Phase III:

**Primary Specification Location** (planning workflow):
- **Path**: `/specs/001-phase-3-chatbot/`
- **Purpose**: Complete planning artifacts generated by `/sp.plan` command
- **Contents**:
  - `spec.md` - Consolidated feature specification (all user stories, NFRs)
  - `plan.md` - Implementation plan template
  - `tasks.md` - 40 granular tasks for implementation
  - `research.md` - Phase 0 research with architectural decisions
  - `data-model.md` - SQLModel definitions for Conversation and Message
  - `quickstart.md` - Developer onboarding guide
  - `contracts/` - API contracts (chat-api-contract.md, mcp-tools-contract.md)

**Feature-Specific Specification Location**:
- **Path**: `/specs/features/phase-3-chatbot/`
- **Purpose**: Feature-level specifications with detailed agent and MCP specs
- **Contents**:
  - `spec.md` - Feature-level specification
  - `agent-spec.md` - OpenAI Agents SDK integration specifications
  - `mcp-tools-spec.md` - Official MCP SDK tool definitions
  - `CONSTITUTION.md` - Phase III-specific governance
  - `plan.md`, `tasks.md` - Feature-level plans

**Spec Organization Principles**:
- **Two-Location Strategy**: Planning artifacts in `001-phase-3-chatbot/`, feature specs in `features/phase-3-chatbot/`
- **Cross-References**: Both locations must stay synchronized
- **Implementation Priority**: Use `001-phase-3-chatbot/tasks.md` as execution order
- **Feature Details**: Use `features/phase-3-chatbot/agent-spec.md` and `mcp-tools-spec.md` for implementation details

**Required Content for AI Features**:
- Agent behavior specifications (intent recognition, tool selection, confirmation flows)
- MCP tool JSON schemas (parameters, return types, error cases) - EXACTLY 5 tools:
  1. `add_task` - user_id, title, description ‚Üí task_id, status, title
  2. `list_tasks` - user_id, status (all/pending/completed) ‚Üí array of tasks
  3. `complete_task` - user_id, task_id ‚Üí task_id, status, title
  4. `delete_task` - user_id, task_id ‚Üí task_id, status, title
  5. `update_task` - user_id, task_id, title, description ‚Üí task_id, status, title
- Conversation flow diagrams (stateless request cycle)
- Natural language command examples (from Hackathon II requirements)
- Performance budgets: Chat response < 3 seconds (p95), MCP tools < 500ms

**Rationale**: Dual-location specs support both systematic planning (001-/) and feature-specific detail (features/), ensures Hackathon II requirements are captured in machine-readable format, enables Claude Code to reference precise implementation details.

---

### II. Clean Code & Multi-Language Standards
All code MUST adhere to language-specific best practices:

**Python (Backend + AI Services)**:
- PEP 8 style guidelines (enforced via ruff)
- Type hints for ALL functions (including async, MCP tools, agent wrappers)
- Descriptive variable names (no single-letter except loop counters)
- Maximum function length: 50 lines (extract helpers if longer)
- Maximum file length: 300 lines (split into modules if longer)
- Docstrings for all public functions, classes, API endpoints, MCP tools
- FastAPI dependency injection for database, auth, agent services
- Structured logging with JSON format (timestamp, trace_id, component, level)

**TypeScript (Frontend + ChatKit Integration)**:
- ESLint + Prettier configured for Next.js 16+
- Strict TypeScript mode enabled (`strict: true`)
- React Server Components by default (Client Components only when needed)
- Component file naming: `PascalCase.tsx` (e.g., `ChatBot.tsx`)
- Utility file naming: `camelCase.ts` (e.g., `chatApi.ts`)
- Maximum component length: 200 lines (extract child components if longer)
- JSDoc comments for complex ChatKit integrations and API clients

**AI-Specific Python Standards**:
- Async/await for all LLM calls and MCP tool invocations
- Type hints for OpenAI SDK returns (Message, ToolCall, AgentResponse)
- Error tracking with full context (user_id, conversation_id, tool_name, trace_id)
- Never expose internal errors to users (log internally, show friendly message)
- Validate MCP tool parameters against JSON Schema before execution
- Always include trace_id for request correlation

**Rationale**: Consistent code quality enables AI-assisted refactoring, prepares for team collaboration, ensures debuggability for complex agent interactions.

---

### III. Test-First Development (TDD)
Testing discipline MUST follow Red-Green-Refactor cycle across all layers:

**Testing Pyramid**:
1. **Unit Tests** (70%):
   - Backend: pytest for business logic, models, utilities, agent logic
   - Frontend: Vitest + React Testing Library for components, hooks
   - **Agent behavior**: Unit tests for intent parsing, tool selection logic (mocked MCP tools)
   - **MCP tools**: Unit tests for parameter validation, error handling (mocked database)
2. **Integration Tests** (20%):
   - Backend: pytest with TestClient for FastAPI routes
   - **Chat endpoint**: Test with mocked Agent SDK and MCP tools
   - Database: Test migrations, queries with test database
   - **MCP tools**: Test tool invocation flow with test database
3. **End-to-End Tests** (10%):
   - Playwright for critical user journeys (signup, login, CRUD, **chat flows**)
   - **Multi-turn chat conversations** (test context preservation, tool usage chaining)

**Phase III Testing Requirements**:
- **Agent behavior tests**:
  ```python
  def test_add_task_intent():
      agent = AgentService(mocked_mcp_tools)
      response = agent.run("Add a task to buy groceries", conversation_history=[])
      assert "add_task" in response.tool_calls
      assert response.tool_calls[0].parameters.title == "Buy groceries"
  ```
- **MCP tool tests** (must mock database):
  ```python
  def test_add_task_tool():
      mcp_server = MCPServer(test_session)
      result = mcp_server.handle_add_task(user_id="test", title="Buy milk")
      assert result["status"] == "created"
      assert "task_id" in result
  ```
- **Conversation flow tests**:
  ```python
  def test_multi_turn_conversation():
      messages = [
          Message(role="user", content="Create task 'Fix bug'"),
          Message(role="assistant", content="Created: Fix bug"),
          Message(role="user", content="Complete it")
      ]
      response = agent.run("Complete it", conversation_history=messages)
      assert "complete_task" in response.tool_calls
  ```

**Requirements**:
- Test coverage target: minimum 80% overall (90% for critical paths)
- All tests MUST run in CI/CD before deployment
- Chat endpoint tests MUST verify user isolation (conversation ownership)
- Agent tests MUST verify error handling (tool failures, malformed input)
- Tests MUST be fast: unit < 1s, integration < 5s, E2E < 30s

**Rationale**: Comprehensive testing prevents regressions in complex agent behaviors, ensures tool reliability, validates natural language understanding accuracy.

---

### IV. Database-First Design with Neon PostgreSQL
Data persistence MUST use Neon Serverless PostgreSQL with SQLModel ORM:

**Phase III Database Models** (from data-model.md):
```python
class Conversation(SQLModel, table=True):
    __tablename__ = "conversations"
    id: UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    user_id: UUID = Field(foreign_key="user.id", index=True)
    title: str | None = Field(None, max_length=255)
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

    messages: List["Message"] = Relationship(back_populates="conversation")
    user: "User" = Relationship(back_populates="conversations")

class Message(SQLModel, table=True):
    __tablename__ = "messages"
    id: UUID = Field(default_factory=uuid.uuid4, primary_key=True)
    conversation_id: UUID = Field(foreign_key="conversations.id", index=True)
    user_id: UUID = Field(foreign_key="user.id", index=True)
    role: str = Field(...)  # "user" or "assistant"
    content: str = Field(...)
    tool_calls: dict | None = Field(None, sa_column_kwargs={"type": "JSONB"})
    created_at: datetime = Field(default_factory=datetime.utcnow)

    conversation: Conversation = Relationship(back_populates="messages")
    user: "User" = Relationship(back_populates="messages")
```

**Migration Strategy**:
- Alembic migration script: `003_add_conversation_tables.py`
- Indexes required:
  - `conversations(user_id, created_at)` - for listing user conversations
  - `messages(conversation_id, created_at)` - for fetching conversation history
- Migration MUST be reversible (include downgrade())

**Conversation Persistence Requirements**:
- All messages stored immediately after generation (user and assistant)
- Tool calls stored as JSONB with structure: `{name: str, parameters: dict, result: dict}`
- Pagination: 1000 message limit per fetch (use offset or cursor-based)
- Retention: 90-day retention policy for archived conversations
- Conversation ownership: ALL queries MUST filter by user_id

**Rationale**: Database-first ensures type-safe queries, enables stateless architecture (no in-memory session state), supports conversation continuity across server restarts.

---

### V. Multi-Interface Excellence (CLI + Web UI + Chatbot)
User interfaces MUST be intuitive, robust, and professional across all access methods:

**Phase I CLI** (Preserved, always accessible):
- Located in `src/todo_app/` (never modified after Phase I completion)
- Numbered menu system, formatted tables, confirmation prompts

**Phase II Web UI** (Preserved, running alongside Phase III):
- Next.js 16+ App Router with Server Components
- Task CRUD operations via REST API
- Responsive design, accessibility (WCAG 2.1 AA)

**Phase III Chatbot UI** (NEW - OpenAI ChatKit):
- **ChatKit Component**: Pre-built web component from OpenAI
- **Integration Point**: `frontend/src/components/ChatBot.tsx`
- **Message Display**:
  - User messages aligned left with timestamp
  - Assistant messages aligned right with tool call summaries
  - Loading indicator during agent processing
  - Error display for tool failures (user-friendly messages)
- **Input Area**:
  - Text input with character count (max 5000 chars)
  - Send button (disabled when empty or processing)
  - Loading spinner during agent execution
- **Conversation History**:
  - Scrollable message list
  - Auto-scroll to latest message
  - Pagination support for long conversations (load more)
- **Accessibility**:
  - Proper ARIA labels for messages and input
  - Keyboard navigation (Tab, Enter to send)
  - Screen reader support for message updates
- **Mobile Responsive**:
  - Touch-friendly interface
  - Optimized for 320px to 4K screens
  - Auto-scroll to keyboard on mobile

**Design System Integration**:
- Use Tailwind CSS for custom ChatKit styling
- Match existing app theme (colors, typography, spacing)
- Ensure ChatKit blends with Task UI components

**Rationale**: ChatKit provides production-ready conversational UI, reduces frontend development time, ensures accessibility and mobile support, allows focus on agent logic.

---

### VI. Modern Technology Stack
Technology standards MUST include latest stable versions and best practices:

**Backend (FastAPI)**:
- Python 3.13+
- FastAPI 0.110+
- SQLModel for ORM
- Pydantic v2 for validation
- UV for dependency management
- pytest + httpx for testing

**Frontend (Next.js)**:
- Next.js 16+ (App Router only)
- React 19+ (Server Components by default)
- TypeScript 5+ (strict mode)
- Tailwind CSS 4+
- Vitest + React Testing Library
- Playwright for E2E

**AI & Chatbot (Phase III - CURRENT PHASE)**:
- **Agent Framework**: OpenAI Agents SDK (official Python SDK)
  - Installation: `uv add openai`
  - Model: `gpt-4-turbo`
  - Temperature: `0.7` (balance creativity and determinism)
  - System prompt: Custom for todo management operations
- **UI Framework**: OpenAI ChatKit (web component)
  - Installation: `pnpm add @openai/chatkit`
  - Integration: React wrapper component
- **Tool Protocol**: Official MCP SDK (Model Context Protocol)
  - Installation: `uv add mcp`
  - Tools: Exactly 5 (add_task, list_tasks, complete_task, delete_task, update_task)
  - Server: Standalone MCP server process (Python)
- **Conversation Persistence**: Neon PostgreSQL (from Phase II)
  - Tables: conversations, messages
  - JSON storage for tool_calls (JSONB column)

**Database**:
- Neon Serverless PostgreSQL
- Alembic for migrations
- Connection pooling enabled

**Authentication**:
- Better Auth (provider)
- JWT tokens (HS256)
- HttpOnly cookies (storage)

**Event-Driven Architecture (Phase V - Not Yet Started)**:
- Apache Kafka / Redpanda Cloud
- Dapr (Distributed Application Runtime)
- Kubernetes / Minikube
- Helm Charts

**Rationale**: Modern stack ensures performance, security, developer experience, alignment with Hackathon II requirements (OpenAI Agents SDK, Official MCP SDK mandatory).

---

### VII. Monorepo Organization
The project MUST support all phases coexisting in a single repository:

**Directory Structure** (updated for Phase III):
```
phase-1/                    # Root (unchanged name for compatibility)
‚îú‚îÄ‚îÄ .specify/               # Spec-Kit Plus (global)
‚îÇ   ‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constitution.md # This file
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ scripts/
‚îú‚îÄ‚îÄ .claude/                # Claude Code config (global)
‚îÇ   ‚îú‚îÄ‚îÄ agents/             # Subagent definitions
‚îÇ   ‚îî‚îÄ‚îÄ skills/             # Reusable intelligence
‚îú‚îÄ‚îÄ specs/                  # ALL specifications
‚îÇ   ‚îú‚îÄ‚îÄ 001-phase-3-chatbot/  # Planning workflow artifacts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spec.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plan.md
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.md        # 40 implementation tasks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ research.md     # Architectural decisions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data-model.md   # Conversation & Message models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quickstart.md   # Developer onboarding
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ contracts/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ chat-api-contract.md
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ mcp-tools-contract.md
‚îÇ   ‚îî‚îÄ‚îÄ features/           # Feature-specific specs
‚îÇ       ‚îî‚îÄ‚îÄ phase-3-chatbot/
‚îÇ           ‚îú‚îÄ‚îÄ spec.md
‚îÇ           ‚îú‚îÄ‚îÄ agent-spec.md       # OpenAI Agents SDK specs
‚îÇ           ‚îú‚îÄ‚îÄ mcp-tools-spec.md   # MCP tool definitions
‚îÇ           ‚îú‚îÄ‚îÄ plan.md
‚îÇ           ‚îú‚îÄ‚îÄ tasks.md
‚îÇ           ‚îî‚îÄ‚îÄ CONSTITUTION.md
‚îú‚îÄ‚îÄ history/                # Global history
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ constitution/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ phase-3-chatbot/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ general/
‚îÇ   ‚îî‚îÄ‚îÄ adr/
‚îú‚îÄ‚îÄ src/                    # Phase I (preserved)
‚îÇ   ‚îî‚îÄ‚îÄ todo_app/
‚îú‚îÄ‚îÄ frontend/               # Phase II+ (Next.js)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ TaskList.tsx
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ChatBot.tsx  # Phase III - ChatKit wrapper (to be created)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chatApi.ts   # Phase III - Chat endpoint client (to be created)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ conversation.ts  # Phase III types (to be created)
‚îÇ   ‚îî‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ backend/                # Phase II+ (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tasks.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.py      # Phase III - POST /api/{user_id}/chat (to be created)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ user.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ conversation.py  # Phase III - Conversation & Message models (to be created)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_service.py
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent_service.py  # Phase III - OpenAI Agents SDK wrapper (to be created)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mcp_service.py    # Phase III - MCP tool definitions (to be created)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ db/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ migrations/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ versions/
‚îÇ   ‚îÇ               ‚îî‚îÄ‚îÄ 003_add_conversation_tables.py  # Phase III migration (to be created)
‚îÇ   ‚îî‚îÄ‚îÄ CLAUDE.md
‚îî‚îÄ‚îÄ CLAUDE.md               # Root instructions
```

**Phase Independence**:
- Phase I: `uv run python -m src.todo_app.main`
- Phase II: `cd frontend && pnpm dev` + `cd backend && uv run uvicorn src.main:app`
- Phase III: Same as Phase II (chat endpoint extends Phase II services)

**Rationale**: Monorepo enables phase coexistence, facilitates shared tooling, allows independent demos.

---

### VIII. Full-Stack Architecture Patterns
Frontend and backend MUST follow clean architecture with clear boundaries:

**Phase III Chat Architecture** (from quickstart.md):
```
User Input (ChatKit) ‚Üí POST /api/{user_id}/chat (FastAPI)
    ‚Üì
Verify JWT Token + User Ownership
    ‚Üì
Fetch or Create Conversation (Database)
    ‚Üì
Fetch Message History (last N messages or full conversation)
    ‚Üì
Build Message Array (System Prompt + History + New Message)
    ‚Üì
Initialize Agent (OpenAI Agents SDK + MCP Tools)
    ‚Üì
Agent.run() - LLM evaluates and selects tools
    ‚Üì
Tool Invocation (MCP Server executes tools)
    ‚Üì
Tool Results Processed by Agent
    ‚Üì
Agent Generates Response (with tool call summaries)
    ‚Üì
Store User Message in Database (conversations.messages)
    ‚Üì
Store Agent Response in Database (with tool_calls JSONB)
    ‚Üì
Return Response to ChatKit UI
```

**Backend Layer Responsibilities**:
- **API Layer** (`api/chat.py`): Thin controller, validates JWT, delegates to services
- **Service Layer** (`services/agent_service.py`, `services/mcp_service.py`): Business logic, agent orchestration, tool execution
- **Model Layer** (`models/conversation.py`): Database schema + Pydantic validation
- **Auth Layer** (`auth/dependencies.py`): JWT verification, user extraction

**State Management**:
- **Server State**: STATELESS - All state in database
- **Conversation State**: Fetched from database on every request
- **No In-Memory Sessions**: Any backend instance can handle any request
- **Client State**: ChatKit manages UI state (message list, input, loading)

**Rationale**: Stateless architecture enables horizontal scaling, clear separation enables parallel development, database-only state ensures resilience.

---

### IX. API Security & Authentication
All API endpoints MUST implement secure authentication and authorization:

**Chat Endpoint Security** (Phase III):
- **Endpoint**: `POST /api/{user_id}/chat`
- **Authentication**: Requires valid JWT token in HttpOnly cookie
- **Authorization**:
  - Extract `user_id` from JWT claims
  - Verify JWT `user_id` matches URL `user_id` parameter
  - Conversation ownership verified (conversation.user_id == current_user.id)
- **Rate Limiting**:
  - 60 messages/minute per user (prevent LLM token abuse)
  - 1000 messages/hour per IP (prevent DoS)
  - Return 429 with Retry-After header if exceeded
- **Input Validation**:
  - Message length: 1-5000 characters
  - Conversation ID: Valid UUID or null (creates new)
  - Sanitize message content (prevent injection)
- **Output Sanitization**:
  - Never expose MCP tool internal errors to user
  - Never expose stack traces or database errors
  - Log errors internally with trace_id for debugging
  - Return user-friendly generic messages ("That operation failed. Please try again")

**JWT Token Standards**:
- Algorithm: HS256
- Expiration: 15 minutes (access token)
- Refresh: 7 days (refresh token)
- Claims: `user_id`, `email`, `exp`, `iat`
- Secret: 256-bit random string (environment variable)

**Rationale**: JWT stateless auth enables horizontal scaling, conversation ownership prevents cross-user leaks, rate limiting prevents abuse.

---

### X. Database-First Design Workflow
Database schema MUST be designed before API implementation:

**Phase III Workflow** (from tasks.md TASK-001):
1. **Spec**: Review database schema in `data-model.md`
2. **Model**: Create `backend/src/models/conversation.py` with Conversation and Message classes
3. **Migration**: Generate Alembic migration `003_add_conversation_tables.py`
4. **Review**: Verify migration creates:
   - `conversations` table with user_id foreign key
   - `messages` table with conversation_id and user_id foreign keys
   - Indexes on (user_id, created_at) and (conversation_id, created_at)
5. **Apply**: `uv run alembic upgrade head`
6. **Test**: Write unit tests for model constraints

**Conversation Persistence**:
- Store ALL messages immediately after generation
- Store tool calls as JSONB: `{name: str, parameters: dict, result: dict}`
- Pagination support: Limit 1000 messages per fetch
- Retention: 90-day retention policy (archive older conversations)
- Ownership verification: ALL queries MUST filter by user_id

**Rationale**: Database-first ensures type-safe queries, enables stateless API, supports conversation continuity.

---

### XI. Subagent Coordination & Parallel Execution
Complex tasks MUST leverage Claude Code subagents for efficiency:

**Phase III Subagent Patterns**:
1. **Feature Swarm** (parallel implementation):
   - Subagent A: Backend API chat endpoint (`api/chat.py`)
   - Subagent B: Frontend ChatBot component (`ChatBot.tsx`)
   - Subagent C: MCP tool definitions (`mcp_service.py`)
   - Subagent D: Agent service wrapper (`agent_service.py`)
   - Coordinator: Integrates and validates all components

2. **Sequential Pipeline** (database-first):
   - Subagent 1: Creates Conversation & Message models
   - Subagent 2: Generates Alembic migration
   - Subagent 3: Implements MCP tools
   - Subagent 4: Implements agent service
   - Subagent 5: Implements chat endpoint

3. **Specialist Agents** (defined in `.claude/agents/`):
   - `rag-chatbot-architect`: Specializes in chatbot architecture
   - `todo-orchestrator`: Hackathon-specific orchestration
   - `testing-qa-validator`: Comprehensive testing
   - `database-architect`: Schema design and migrations

**Context7 MCP Integration**:
- Query OpenAI Agents SDK documentation for latest patterns
- Query Official MCP SDK for tool definition schemas
- Query ChatKit documentation for integration patterns
- Validate generated code against official docs

**Rationale**: Subagents accelerate development, Context7 ensures modern patterns, specialist agents capture domain expertise.

---

### XII. Reusable Intelligence via Skills
Common patterns MUST be extracted into reusable Claude Code skills:

**Phase III Skills** (to be created):
1. **AI/Chatbot Skills**:
   - `create-mcp-tool`: Generate MCP tool with JSON schema validation
   - `create-agent-service`: Generate OpenAI Agents SDK wrapper
   - `test-agent-behavior`: Generate tests for intent parsing and tool selection
   - `create-chatkit-component`: Generate ChatKit wrapper component

**Skill Format**:
```markdown
# Skill: Create MCP Tool

## Description
Generates an MCP tool definition with JSON Schema validation.

## Inputs
- tool_name: snake_case (e.g., add_task)
- description: Human-readable purpose
- parameters: JSON Schema object
- implementation: Python function logic

## Process
1. Generate JSON Schema for parameters
2. Add parameter validation
3. Create tool handler function
4. Return tool configuration dict

## Example Usage
/skill create-mcp-tool \
  --name add_task \
  --description "Create a new task" \
  --parameters '{"title": {"type": "string"}, "description": {"type": "string"}}'
```

**Rationale**: Skills reduce repetitive subagent invocations, ensure consistency across features.

---

### XIII. AI Agent Architecture (Phase III - CORE PRINCIPLE)
All AI agent implementations MUST use OpenAI Agents SDK following strict patterns:

**Agent Initialization** (from quickstart.md):
```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# Initialize agent with MCP tools
response = client.chat.completions.create(
    model="gpt-4-turbo",
    temperature=0.7,
    messages=[
        {"role": "system", "content": "You are a helpful todo assistant. Use the provided tools to manage tasks..."},
        {"role": "user", "content": user_message}
    ],
    tools=mcp_tools,  # List of MCP tool definitions
)
```

**Agent Behavior Requirements** (from agent-spec.md):
- **Tool Selection**: Choose appropriate tool based on user intent
- **Parameter Extraction**: Correctly parse user input into tool parameters
- **Confirmation**: Confirm destructive operations (delete, update) before execution
- **Error Recovery**: Handle tool failures gracefully with user-friendly messages
- **Context Awareness**: Maintain conversation context across multiple turns
- **Token Management**: Respect context window limits (track message count, trim history if needed)

**System Prompt Design**:
```
You are a helpful todo assistant. Use the provided tools to manage tasks.

TOOLS AVAILABLE:
- add_task: Create new task (parameters: title, description)
- list_tasks: Retrieve tasks (parameters: status: all/pending/completed)
- complete_task: Mark task done (parameters: task_id)
- delete_task: Remove task (parameters: task_id)
- update_task: Modify task (parameters: task_id, title, description)

BEHAVIOR GUIDELINES:
- Always confirm task creation with details ("Created: Buy groceries")
- Ask for confirmation before deletion ("Are you sure you want to delete 'Old task'?")
- Provide helpful error messages ("Task not found. Try 'Show me my tasks'")
- Maintain context across conversation turns
```

**Tool Selection Logic** (from Hackathon II requirements):
| User Says | Intent | Tool Called |
|-----------|--------|-------------|
| "Add a task to buy groceries" | create_task | add_task(title="Buy groceries") |
| "Show me all my tasks" | list_tasks | list_tasks(status="all") |
| "Mark task 3 as complete" | complete_task | complete_task(task_id=3) |
| "Delete the meeting task" | delete_task | list_tasks first, then delete_task |
| "Change task 1 to 'Call mom'" | update_task | update_task(task_id=1, title="Call mom") |

**Context Management**:
- Fetch full conversation history on new message
- Build message array: [system_prompt, historical_messages, new_message]
- Limit history: Keep last N messages (or 90 days, whichever first)
- Store all exchanges in database (enable conversation resume)

**Error Handling**:
- Tool not found: "I couldn't perform that action. Try saying 'Show me my tasks'"
- Tool parameter error: "I didn't understand that. Could you rephrase?"
- Tool execution error: "That operation failed. Please try again"

**Rationale**: Standardized agent architecture ensures predictable behavior, enables testing, provides clear error handling.

---

### XIV. MCP Server Design (Phase III - CORE PRINCIPLE)
Official MCP SDK MUST be used for standardized tool interface:

**MCP Tool Definitions** (EXACTLY 5 - from Hackathon II):

**Tool 1: add_task**
```json
{
  "name": "add_task",
  "description": "Create a new task for the user",
  "parameters": {
    "type": "object",
    "properties": {
      "user_id": {"type": "string", "description": "User UUID"},
      "title": {"type": "string", "minLength": 1, "maxLength": 200},
      "description": {"type": "string", "maxLength": 2000}
    },
    "required": ["user_id", "title"]
  },
  "return": {
    "task_id": "string (UUID)",
    "status": "created | error",
    "title": "string"
  }
}
```

**Tool 2: list_tasks**
```json
{
  "name": "list_tasks",
  "description": "Retrieve tasks for the user with optional status filter",
  "parameters": {
    "type": "object",
    "properties": {
      "user_id": {"type": "string"},
      "status": {"type": "string", "enum": ["all", "pending", "completed"]}
    },
    "required": ["user_id"]
  },
  "return": "array of task objects"
}
```

**Tool 3: complete_task**
```json
{
  "name": "complete_task",
  "description": "Mark a task as complete",
  "parameters": {
    "type": "object",
    "properties": {
      "user_id": {"type": "string"},
      "task_id": {"type": "string"}
    },
    "required": ["user_id", "task_id"]
  },
  "return": {
    "task_id": "string",
    "status": "completed | error",
    "title": "string"
  }
}
```

**Tool 4: delete_task, Tool 5: update_task**: (Similar structure, from mcp-tools-spec.md)

**Implementation Standards**:
- Each tool is a STATELESS Python async function
- Function signature matches JSON Schema parameters
- Return structured JSON response: `{success: bool, data: dict, error: str | None}`
- All database operations wrapped in transactions
- Proper error handling with descriptive messages
- Ownership verification on all operations (user_id must match)

**Performance Requirements**:
- Tool execution < 500ms (99th percentile)
- Database queries use indexes
- Connection pooling enabled
- Rate limiting enforced per user

**Stateless Design**:
- Tools never maintain in-memory state
- Tools never cache data (database is source of truth)
- Tools never depend on previous invocations
- Any server instance can execute any tool

**Rationale**: Standardized MCP tools enable agent consistency, stateless design enables horizontal scaling, JSON Schema prevents invalid requests.

---

### XV. Conversation State Management (Phase III - CORE PRINCIPLE)
Conversation state MUST be persisted to database with stateless endpoints:

**Stateless Endpoint Flow** (from chat-api-contract.md):
```python
@app.post("/api/{user_id}/chat")
async def chat(user_id: UUID, request: ChatRequest,
               current_user: User = Depends(get_current_user)):
    # 1. Verify ownership
    if user_id != current_user.id:
        raise HTTPException(403, "Access denied")

    # 2. Fetch or create conversation
    conversation = session.get(Conversation, request.conversation_id)
    if not conversation:
        conversation = Conversation(user_id=user_id)
        session.add(conversation)
        session.commit()

    # 3. Fetch message history
    messages = session.exec(select(Message)
        .where(Message.conversation_id == conversation.id)
        .order_by(Message.created_at)).all()

    # 4. Store user message
    user_msg = Message(conversation_id=conversation.id,
                       user_id=user_id, role="user", content=request.message)
    session.add(user_msg)
    session.commit()

    # 5. Run agent with full history
    agent_response = await agent_service.run_agent(
        user_message=request.message,
        conversation_history=messages,
        mcp_tools=mcp_tools,
        user_id=user_id
    )

    # 6. Store assistant response
    assistant_msg = Message(conversation_id=conversation.id,
                           user_id=user_id, role="assistant",
                           content=agent_response.content,
                           tool_calls=agent_response.tool_calls)
    session.add(assistant_msg)
    session.commit()

    # 7. Return response (no in-memory state retained)
    return ChatResponse(conversation_id=conversation.id,
                       response=agent_response.content,
                       tool_calls=agent_response.tool_calls)
```

**Chat Endpoint API** (from chat-api-contract.md):
```
POST /api/{user_id}/chat
Content-Type: application/json
Authorization: Bearer <JWT>

Request:
{
  "conversation_id": "uuid | null (creates new)",
  "message": "string (1-5000 chars)"
}

Response (200):
{
  "conversation_id": "uuid",
  "message_id": "uuid",
  "response": "string",
  "tool_calls": [
    {"name": "tool_name", "parameters": {...}, "result": {...}}
  ],
  "timestamp": "ISO8601"
}
```

**Conversation Limits**:
- Message limit: 1000 messages per conversation
- Retention: 90-day retention policy
- Context window: Use last N messages for agent
- Rate limiting: 60 messages/minute per user

**Statelessness Benefits**:
- Any backend instance can handle any request
- Server restarts don't lose conversation state
- Horizontal scaling without session affinity
- Database is single source of truth

**Rationale**: Database-backed state enables stateless architecture, supports scalability, provides conversation history.

---

### XVI. Natural Language Understanding (Phase III - CORE PRINCIPLE)
Agent MUST correctly understand and execute natural language commands:

**Intent Recognition Examples** (from Hackathon II):
| User Says | Detected Intent | Tool Called |
|-----------|-----------------|------------|
| "Add a task to buy groceries" | create_task | add_task(title="Buy groceries") |
| "Show me all my tasks" | list_tasks | list_tasks(status="all") |
| "What's pending?" | list_tasks | list_tasks(status="pending") |
| "Mark task 3 as complete" | complete_task | complete_task(task_id=3) |
| "Delete the meeting task" | delete_task | list_tasks + delete_task |
| "I need to remember to pay bills" | create_task | add_task(title="Pay bills") |
| "What have I completed?" | list_tasks | list_tasks(status="completed") |
| "Change task 1 to 'Call mom tonight'" | update_task | update_task(task_id=1, title="Call mom tonight") |

**Confirmation Protocol**:
- **Create**: Confirm with task details ("Created: Buy groceries")
- **Update**: Confirm with new details ("Updated to: Call mom tonight")
- **Delete**: ASK FOR CONFIRMATION ("Are you sure you want to delete 'Old task'?")
- **Complete**: Confirm with task name ("Marked complete: Buy groceries")

**Multi-Turn Context Awareness**:
- Remember task references across turns
- Pronoun resolution ("delete it" = last mentioned task)
- State preservation (agent knows listed tasks)
- Clarification requests ("Did you mean task #1 or #2?")

**Testing Patterns**:
```python
def test_add_task_intent():
    intent = parse_intent("Add a task to buy groceries")
    assert intent.tool_name == "add_task"
    assert intent.parameters.title == "Buy groceries"

def test_multi_turn_context():
    messages = [
        Message(role="user", content="Create task 'Fix bug'"),
        Message(role="user", content="Complete it")
    ]
    intent = parse_intent_with_context("Complete it", messages)
    assert intent.task_id == created_task_id
```

**Rationale**: Natural language understanding enables non-technical users, context awareness enables multi-turn conversations.

---

### XVII. Error Handling & Resilience (Phase III - CORE PRINCIPLE)
All error scenarios MUST be handled gracefully with clear user feedback:

**User-Friendly Error Messages**:
- ‚ùå BAD: "Traceback: IndexError on line 42"
- ‚úÖ GOOD: "I couldn't find that task"

- ‚ùå BAD: "Foreign key constraint violation"
- ‚úÖ GOOD: "Task not found. Try 'Show me my tasks'"

- ‚ùå BAD: "Connection timeout to Neon"
- ‚úÖ GOOD: "I'm having trouble accessing your tasks. Please try again in a moment"

**Rate Limiting**:
- Per-user: 60 messages/minute
- Per-IP: 1000 messages/hour
- Graceful degradation: Return 429 with retry-after header
- User message: "You're chatting too fast. Please wait a moment"

**Error Handling Examples**:
```python
# Missing required parameter
if not request.message or not request.message.strip():
    raise HTTPException(400, "Message cannot be empty")

# Resource not found
task = session.get(Task, task_id)
if not task:
    raise HTTPException(404, "Task not found")

# Tool execution error
try:
    result = execute_tool(tool_name, parameters)
except ToolExecutionError as e:
    logger.error(f"Tool error: {e}", extra={"trace_id": trace_id})
    return {"status": "error", "message": "That operation failed. Please try again"}
```

**Resilience Patterns**:
- Retry transient failures with exponential backoff
- Circuit breaker for failing external services
- Timeout all external calls (LLM, MCP tools)
- Fallback responses when services unavailable

**Rationale**: Clear error messages improve UX, graceful degradation ensures resilience.

---

### XVIII. Observability for AI Systems (Phase III - CORE PRINCIPLE)
AI operations MUST be fully observable with structured logging and metrics:

**Structured Logging Format**:
```json
{
  "timestamp": "2025-12-21T14:30:45.123Z",
  "level": "INFO",
  "message": "Agent response generated",
  "trace_id": "abc123def456",
  "user_id": "user-uuid",
  "conversation_id": "conv-uuid",
  "component": "agent",
  "agent_action": "tool_invoked",
  "tool_name": "add_task",
  "tool_duration_ms": 145,
  "tool_success": true,
  "llm_tokens_used": 342,
  "llm_model": "gpt-4-turbo",
  "request_duration_ms": 2103
}
```

**Logging Points**:
1. Agent initialized: "Agent initialized with 5 tools, model: gpt-4-turbo"
2. Message received: "Received message: 'Add task...', length: 23"
3. Tool invoked: "Tool: add_task, parameters: {title: 'Buy milk'}, duration: 145ms"
4. Tool result: "Tool result: {task_id: 123}, success: true"
5. Agent response: "Agent response generated, tokens: 342, duration: 2103ms"

**Metrics Tracked**:
- **Performance**: Messages/min, response time (p50, p95, p99), tool execution time
- **Reliability**: Tool success rate, error rate, timeout rate
- **Usage**: Unique users/day, messages/user/day, tool usage distribution
- **Cost**: LLM tokens consumed, API costs

**Tracing**:
- Every chat request gets unique `trace_id` (UUID format)
- All logs from same request include trace_id
- Enable end-to-end request tracking
- Correlate logs across components

**Debugging Support**:
- Log full request/response for sample (1% sampling)
- Log full MCP tool calls and results
- Log agent decision rationale (which tool, why)
- Sanitize sensitive data (passwords, tokens)

**Rationale**: Structured logging enables quick debugging, metrics track system health, tracing correlates events.

---

## Technology Standards

**Required Stack**:

**Backend**:
- Python 3.13+, FastAPI 0.110+, SQLModel, Neon PostgreSQL, Alembic, UV, pytest, ruff

**Frontend**:
- Next.js 16+ (App Router), TypeScript 5+ (strict), Tailwind CSS 4+, OpenAI ChatKit, pnpm, Vitest, Playwright

**AI & Chatbot (Phase III - Current)**:
- **Agent**: OpenAI Agents SDK (official), GPT-4-turbo, temperature=0.7
- **UI**: OpenAI ChatKit (web component)
- **Tools**: Official MCP SDK (5 tools: add_task, list_tasks, complete_task, delete_task, update_task)
- **Conversation DB**: Neon PostgreSQL (Conversation & Message models)

**Event-Driven (Phase IV+)**:
- Kafka / Redpanda Cloud, Dapr, Kubernetes / Minikube, Helm, kubectl-ai, kagent

**Authentication**:
- Better Auth, JWT (HS256), HttpOnly cookies

**DevOps**:
- Git + GitHub, GitHub Actions, Vercel (frontend), Railway/Render (backend), Neon (database)

---

## Development Workflow

**Phase III Implementation Cycle**:
1. **Read Specs**: Review `001-phase-3-chatbot/tasks.md` (40 tasks)
2. **Database First**: Create Conversation & Message models, generate migration
3. **Parallel Development**:
   - Backend: Implement chat endpoint + agent service + MCP tools
   - Frontend: Implement ChatBot component with ChatKit
4. **Agent Testing**: Test intent parsing, tool selection, error handling
5. **Integration**: Connect ChatBot to chat endpoint
6. **E2E Testing**: Test multi-turn conversations with Playwright
7. **Review**: Verify all 40 tasks completed
8. **Document**: Update README with chatbot usage
9. **Commit**: Create PHR in `history/prompts/phase-3-chatbot/`
10. **Deploy**: Push to staging, run E2E tests, deploy to production

**Quality Gates**:
- ‚úÖ All tests pass (backend pytest, frontend vitest, E2E playwright)
- ‚úÖ Type checking passes (tsc --noEmit, mypy)
- ‚úÖ Linting passes (eslint, ruff)
- ‚úÖ Spec acceptance criteria met (all 40 tasks marked [X])
- ‚úÖ Performance budgets met (chat response < 3s p95)
- ‚úÖ Agent behavior validated (intent recognition, tool usage)
- ‚úÖ MCP tools validated (5 tools working correctly)

---

## Governance

**Amendment Process**:
1. Documented rationale
2. Impact analysis
3. Semantic version increment
4. Update constitution with sync impact report
5. Update affected templates
6. Create ADR if significant

**Versioning Policy**:
- **MAJOR**: Backward-incompatible changes, architecture redesigns
- **MINOR**: New principles/sections (backward compatible)
- **PATCH**: Clarifications, wording improvements

**Compliance**:
- All implementations MUST comply with these principles
- Claude Code MUST verify compliance before code generation
- Deviations require explicit justification in spec or ADR
- Constitution supersedes external docs

**Runtime Guidance**:
- Root: `CLAUDE.md` - General workflows, PHR creation
- Frontend: `frontend/CLAUDE.md` - Next.js patterns
- Backend: `backend/CLAUDE.md` - FastAPI patterns

**Version**: 3.1.0 | **Ratified**: 2025-12-06 | **Last Amended**: 2025-12-13
